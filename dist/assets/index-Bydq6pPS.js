import{M as x}from"./MipmapFilter-nkAaR1eK.js";import{v,V as M,j as G,F as i}from"./uwal-C6J7qtYI.js";import{v as D,a as n}from"./wgpu-matrix.module-3qzuEYdi.js";const _=""+new URL("../videos/retriever.webm",import.meta.url).href;/**
 * @module Loading Video
 * @author Ustym Ukhman <ustym.ukhman@gmail.com>
 * @description This lesson is reproduced from WebGPU Loading Images into Textures
 * {@link https://webgpufundamentals.org/webgpu/lessons/webgpu-importing-textures.html#loading-video}&nbsp;
 * and developed by using a version listed below. Please note that this code
 * may be simplified in future thanks to more recent library APIs.
 * @version 0.0.5
 * @license MIT
 */(async function(E){let t;try{t=new(await v.RenderPipeline(E,"Loading Video"))}catch(e){alert(e)}const I=0,p=[],f=1,T=2e3,b=[0,1,0],w=[0,0,0],R=Math.PI*60/180,L=[0,0,2],F=D.set(1.2,.7),u=n.perspective(R,t.AspectRatio,f,T),A=n.inverse(n.lookAt(L,w,b)),S=n.multiply(u,A),r=document.createElement("video");r.muted=r.loop=!0,r.preload="auto",r.src=_;const c=new(await v.LegacyTexture());c.SetRenderer(t);let l=!1;await h(r);const C=V(r,!0),P=!("requestVideoFrameCallback"in r);t.CreatePipeline({module:t.CreateShaderModule([M.Quad,x])});const y=t.CreateColorAttachment();if(y.clearValue=new G(5000268).rgba,t.CreatePassDescriptor(y),!P){const e=()=>{r.requestVideoFrameCallback(e),l=!0};r.requestVideoFrameCallback(e)}for(let e=0;e<8;e++){const o=c.CreateSampler({addressModeU:i.ADDRESS.REPEAT,addressModeV:i.ADDRESS.REPEAT,magFilter:e&1?i.FILTER.LINEAR:i.FILTER.NEAREST,minFilter:e&2?i.FILTER.LINEAR:i.FILTER.NEAREST,mipmapFilter:e&4?i.FILTER.LINEAR:i.FILTER.NEAREST}),s=16*Float32Array.BYTES_PER_ELEMENT,a=t.CreateBuffer({usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST,size:s}),d=new Float32Array(s/Float32Array.BYTES_PER_ELEMENT),m=d.subarray(I,16);t.AddBindGroups(t.CreateBindGroup(t.CreateBindGroupEntries([o,C.createView(),{buffer:a}]))),p.push({matrixBuffer:a,matrixValues:d,matrix:m})}function V(e,o=!1){return c.CopyImageToTexture(e,{create:{usage:GPUTextureUsage.RENDER_ATTACHMENT|GPUTextureUsage.TEXTURE_BINDING|GPUTextureUsage.COPY_DST,format:"rgba8unorm",mipmaps:o}})}function h(e){return new Promise((o,s)=>{if(e.addEventListener("error",s),"requestVideoFrameCallback"in e)e.requestVideoFrameCallback(o);else{const a=()=>e.currentTime?o():requestAnimationFrame(a);a()}e.play().catch(s)})}function g(){requestAnimationFrame(g),(P||l)&&(c.CopyImageToTexture(r,{texture:C}),l=!1),p.forEach(({matrix:e,matrixBuffer:o,matrixValues:s},a)=>{const m=a%4-1.5,N=+(a<4)*2-1,U=[m*F[0],N*F[1],-50*.5];n.translate(S,U,e),n.rotateX(e,Math.PI*.5,e),n.scale(e,[1,100,1],e),n.translate(e,[-.5,-.5,0],e),t.WriteBuffer(o,s),t.SetActiveBindGroups(a),t.Render(6,!1)}),t.Submit()}const B=new ResizeObserver(e=>{for(const o of e){const{inlineSize:s,blockSize:a}=o.contentBoxSize[0];t.SetCanvasSize(s,a)}n.perspective(R,t.AspectRatio,f,T,u),n.multiply(u,A,S),requestAnimationFrame(g)});E.addEventListener("click",()=>r[r.paused?"play":"pause"]()),B.observe(document.body)})(document.getElementById("lesson"));
