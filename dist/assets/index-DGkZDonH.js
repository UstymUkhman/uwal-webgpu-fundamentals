import{v as A,G as I,j as L,V as s}from"./uwal-BNRo3Xsn.js";import{v as M,a}from"./wgpu-matrix.module-3qzuEYdi.js";var G="struct Transform{matrix: mat4x4f};struct VertexOutput{@builtin(position)position: vec4f,@location(0)textureCoord: vec2f};@group(0)@binding(0)var Sampler: sampler;@group(0)@binding(1)var Texture: texture_external;@group(0)@binding(2)var<uniform>transform: Transform;@vertex fn vertex(@builtin(vertex_index)index: u32)->VertexOutput {var output: VertexOutput;var position=GetQuadCoord(index);position=(position+1)*0.5;output.position=transform.matrix*vec4f(position,0.0,1.0);output.textureCoord=position;return output;}@fragment fn fragment(@location(0)textureCoord: vec2f)->@location(0)vec4f {return textureSampleBaseClampToEdge(Texture,Sampler,textureCoord);}";const U=""+new URL("../videos/pomeranian.mp4",import.meta.url).href;/**
 * @module Using Video
 * @author Ustym Ukhman <ustym.ukhman@gmail.com>
 * @description This lesson is reproduced from WebGPU Using Video Efficiently
 * {@link https://webgpufundamentals.org/webgpu/lessons/webgpu-textures-external-video.html}&nbsp;
 * and developed by using a version listed below. Please note that this code
 * may be simplified in future thanks to more recent library APIs.
 * @version 0.0.6
 * @license MIT
 */(async function(p){let t;try{t=new(await A.RenderPipeline(p,"Using Video"))}catch(e){alert(e)}const b=0,m=[],d=1,f=2e3,y=[0,1,0],F=[0,0,0],x=Math.PI*60/180,P=[0,0,2],E=M.set(1.2,.5),l=a.perspective(x,t.AspectRatio,d,f),v=a.lookAt(P,F,y),T=a.multiply(l,v),i=document.createElement("video");i.muted=i.loop=!0,i.preload="auto",i.src=U,t.CreatePipeline({module:t.CreateShaderModule([I.Quad,G])});const g=t.CreateColorAttachment();g.clearValue=new L(5000268).rgba,t.CreatePassDescriptor(g);const R=new(await A.LegacyTexture());await V(i);for(let e=0;e<4;e++){const r=R.CreateSampler({magFilter:e&1?s.FILTER.LINEAR:s.FILTER.NEAREST,minFilter:e&2?s.FILTER.LINEAR:s.FILTER.NEAREST,addressModeUV:s.ADDRESS.REPEAT}),o=16*Float32Array.BYTES_PER_ELEMENT,n=t.CreateBuffer({usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST,size:o}),u=new Float32Array(o/Float32Array.BYTES_PER_ELEMENT),c=u.subarray(b,16);m.push({sampler:r,matrixBuffer:n,matrixValues:u,matrix:c})}function V(e){return new Promise((r,o)=>{if(e.addEventListener("error",o),"requestVideoFrameCallback"in e)e.requestVideoFrameCallback(r);else{const n=()=>e.currentTime?r():requestAnimationFrame(n);n()}e.play().catch(o)})}function S(){requestAnimationFrame(S);const e=R.ImportExternalTexture(i);m.forEach(({matrix:r,sampler:o,matrixBuffer:n,matrixValues:u},c)=>{const h=c%2-.5,C=+(c<2)*2-1,w=[h*E[0],C*E[1],-.5];a.translate(T,w,r),a.rotateX(r,Math.PI*.25*Math.sign(C),r),a.scale(r,[1,-1,1],r),a.translate(r,[-.5,-.5,0],r),t.WriteBuffer(n,u),t.SetBindGroups(t.CreateBindGroup(t.CreateBindGroupEntries([o,e,{buffer:n}]))),t.Render(6,!1)}),t.Submit()}const B=new ResizeObserver(e=>{for(const r of e){const{inlineSize:o,blockSize:n}=r.contentBoxSize[0];t.SetCanvasSize(o,n)}a.perspective(x,t.AspectRatio,d,f,l),a.multiply(l,v,T),requestAnimationFrame(S)});p.addEventListener("click",()=>i[i.paused?"play":"pause"]()),B.observe(document.body)})(document.getElementById("lesson"));
